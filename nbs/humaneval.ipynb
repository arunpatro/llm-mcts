{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from human_eval.execution import check_correctness\n",
    "from human_eval.data import HUMAN_EVAL, stream_jsonl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = list(stream_jsonl(HUMAN_EVAL))\n",
    "tid_map = {problem[\"task_id\"]: problem for problem in problems}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "def sum_squares(lst):\n",
      "    \"\"\"\"\n",
      "    This function will take a list of integers. For all entries in the list, the function shall square the integer entry if its index is a \n",
      "    multiple of 3 and will cube the integer entry if its index is a multiple of 4 and not a multiple of 3. The function will not \n",
      "    change the entries in the list whose indexes are not a multiple of 3 or 4. The function shall then return the sum of all entries. \n",
      "    \n",
      "    Examples:\n",
      "    For lst = [1,2,3] the output should be 6\n",
      "    For lst = []  the output should be 0\n",
      "    For lst = [-1,-5,2,-1,-5]  the output should be -126\n",
      "    \"\"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 142\n",
    "problem = problems[idx]\n",
    "print(problem['prompt'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    result =[]\n",
      "    for i in range(len(lst)):\n",
      "        if i %3 == 0:\n",
      "            result.append(lst[i]**2)\n",
      "        elif i % 4 == 0 and i%3 != 0:\n",
      "            result.append(lst[i]**3)\n",
      "        else:\n",
      "            result.append(lst[i])\n",
      "    return sum(result)\n",
      "\n",
      "def check(candidate):\n",
      "\n",
      "    # Check some simple cases\n",
      "    \n",
      "    assert candidate([1,2,3]) == 6\n",
      "    assert candidate([1,4,9]) == 14\n",
      "    assert candidate([]) == 0\n",
      "    assert candidate([1,1,1,1,1,1,1,1,1]) == 9\n",
      "    assert candidate([-1,-1,-1,-1,-1,-1,-1,-1,-1]) == -3\n",
      "    assert candidate([0]) == 0\n",
      "    assert candidate([-1,-5,2,-1,-5]) == -126\n",
      "    assert candidate([-56,-99,1,0,-2]) == 3030\n",
      "    assert candidate([-1,0,0,0,0,0,0,0,-1]) == 0\n",
      "    assert candidate([-16, -9, -2, 36, 36, 26, -20, 25, -40, 20, -4, 12, -26, 35, 37]) == -14196\n",
      "    assert candidate([-1, -3, 17, -1, -15, 13, -1, 14, -14, -12, -5, 14, -14, 6, 13, 11, 16, 16, 4, 10]) == -1448\n",
      "    \n",
      "    \n",
      "    # Don't remove this line:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(problem['canonical_solution'])\n",
    "print(problem[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: should be returning fraction of test cases passed, instead of 0/1\n",
    "def execute(problem, completion, timeout=10):\n",
    "    result = check_correctness(problem, completion, timeout)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return [i for i in range(min(a, b), max(a, b)+1) if i % 2 == 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem = problems[163]\n",
    "completion = \"\\n    return [i for i in range(min(a, b), max(a, b)+1) if i % 2 == 0]\\n\\n\"\n",
    "print(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/142',\n",
       " 'passed': False,\n",
       " 'result': \"failed: name 'a' is not defined\",\n",
       " 'completion_id': None}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute(problem, completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': 'HumanEval/142',\n",
       " 'passed': False,\n",
       " 'result': 'failed: ',\n",
       " 'completion_id': None}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_completion = \"    return False\"\n",
    "execute(problem, incorrect_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pass rate: 92.59%\n"
     ]
    }
   ],
   "source": [
    "mcts_solutions = list(stream_jsonl(\"../few_shot_mcts.jsonl\"))\n",
    "mcts_results = []\n",
    "for solution in mcts_solutions:\n",
    "    problem = tid_map[solution[\"task_id\"]]\n",
    "    completion = solution[\"completion\"]\n",
    "    result = execute(problem, completion)\n",
    "    mcts_results.append(result[\"passed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCTS pass rate: 92.59%\n",
      "Avg num generations: 3.62\n",
      "Avg num rollouts: 15.47\n"
     ]
    }
   ],
   "source": [
    "mcts_pass_rate = 100 * sum(mcts_results) / len(mcts_results)\n",
    "mcts_total_gens = sum([solution[\"stats\"][\"num_generations\"] for solution in mcts_solutions])\n",
    "mcts_mean_gens = mcts_total_gens / len(mcts_solutions)\n",
    "mcts_mean_rollouts = sum([solution[\"stats\"][\"num_rollouts\"] for solution in mcts_solutions]) / len(mcts_solutions)\n",
    "print(f\"MCTS pass rate: {mcts_pass_rate:.2f}%\")\n",
    "print(f\"Avg num generations: {mcts_mean_gens:.2f}\")\n",
    "print(f\"Avg num rollouts: {mcts_mean_rollouts:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_solutions = list(stream_jsonl(\"../few_shot_baselines_256_top_3.jsonl\"))\n",
    "tid_completions_map = {}\n",
    "for solution in baseline_solutions:\n",
    "    tid_completions_map.setdefault(solution[\"task_id\"], []).append(solution[\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "for task_id, completions in tid_completions_map.items():\n",
    "    problem = tid_map[task_id]\n",
    "    result = False\n",
    "    for completion in completions:\n",
    "        r = execute(problem, completion)\n",
    "        if r[\"passed\"]:\n",
    "            result = True\n",
    "            break\n",
    "    baseline_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline pass@20: 90.74%\n"
     ]
    }
   ],
   "source": [
    "baseline_pass_rate = 100 * sum(baseline_results) / len(baseline_results)\n",
    "baseline_k = len(baseline_solutions) / len(baseline_results)\n",
    "print(f\"Baseline pass@{int(baseline_k)}: {baseline_pass_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = []\n",
    "for task_id, completions in tid_completions_map.items():\n",
    "    problem = tid_map[task_id]\n",
    "    result = False\n",
    "    for completion in completions[:5]:\n",
    "        r = execute(problem, completion)\n",
    "        if r[\"passed\"]:\n",
    "            result = True\n",
    "            break\n",
    "    baseline_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline pass@5: 85.80%\n"
     ]
    }
   ],
   "source": [
    "baseline_pass_rate = 100 * sum(baseline_results) / len(baseline_results)\n",
    "print(f\"Baseline pass@5: {baseline_pass_rate:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
