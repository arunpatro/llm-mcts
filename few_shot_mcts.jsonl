{"task_id": "HumanEval/2", "completion": "\n    return abs(number - int(number))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.9628s", "mean_test_time": "2.8062s"}}
{"task_id": "HumanEval/3", "completion": "\n    balance = 0\n    for op in operations:\n        balance += op\n        if balance < 0:\n            return True\n\n    return False\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.8732s", "mean_test_time": "3.2185s"}}
{"task_id": "HumanEval/4", "completion": "\n    mean = sum(numbers) / len(numbers)\n    deviations = [abs(n - mean) for n in numbers]\n    mad = sum(deviations) / len(deviations)\n\n    return mad\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.1757s", "mean_test_time": "2.6800s"}}
{"task_id": "HumanEval/5", "completion": "\n    result = []\n    for idx, num in enumerate(numbers):\n        if idx > 0:\n            result.append(delimeter)\n        result.append(num)\n    return result\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.7962s", "mean_test_time": "2.7157s"}}
{"task_id": "HumanEval/6", "completion": "\n    def count_depth(s):\n        stack = []\n        max_d = 0\n        d = 0\n        for c in s:\n            if c == '(':\n                stack.append(c)\n                d += 1\n                max_d = max(max_d, d)\n            elif c == ')':\n                stack.pop()\n                d -= 1\n        return max_d\n\n    groups = paren_string.split(' ')\n    depths = [count_depth(g) for g in groups]\n    return depths\n", "stats": {"num_rollouts": 4, "num_generations": 2, "eval_time": "17.2326s", "mean_test_time": "2.6231s"}}
{"task_id": "HumanEval/7", "completion": "\n    return [s for s in strings if substring in s]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.4674s", "mean_test_time": "2.7727s"}}
{"task_id": "HumanEval/8", "completion": "\n    sum = 0\n    product = 1\n\n    for num in numbers:\n        sum += num\n        product *= num\n\n    return (sum, product)\n\n", "stats": {"num_rollouts": 3, "num_generations": 2, "eval_time": "12.2120s", "mean_test_time": "2.9819s"}}
{"task_id": "HumanEval/9", "completion": "\n    if not numbers:\n        return []\n\n    result = [numbers[0]]\n    for num in numbers[1:]:\n        result.append(max(result[-1], num))\n\n    return result\n\n", "stats": {"num_rollouts": 8, "num_generations": 3, "eval_time": "18.3149s", "mean_test_time": "2.8283s"}}
{"task_id": "HumanEval/10", "completion": "\n    if is_palindrome(string):\n        return string\n\n    for i in range(len(string)):\n        if is_palindrome(string[i:]):\n            prefix = string[:i]\n            return string + prefix[::-1]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.1612s", "mean_test_time": "3.0379s"}}
{"task_id": "HumanEval/11", "completion": "\n    if len(a) != len(b):\n        raise ValueError(\"Strings must be of the same length\")\n\n    result = []\n    for a_bit, b_bit in zip(a, b):\n        if a_bit == '1' and b_bit == '1':\n            result.append('0')\n        elif a_bit == '0' and b_bit == '0':\n            result.append('0')\n        else:\n            result.append('1')\n    return \"\".join(result)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.2085s", "mean_test_time": "2.6528s"}}
{"task_id": "HumanEval/12", "completion": "\n    if not strings:\n        return None\n\n    longest_string = strings[0]\n    for string in strings:\n        if len(string) > len(longest_string):\n            longest_string = string\n\n    return longest_string\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.2966s", "mean_test_time": "2.6863s"}}
{"task_id": "HumanEval/13", "completion": "\n    while b != 0:\n        a, b = b, a % b\n\n    return abs(a)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.9419s", "mean_test_time": "2.8486s"}}
{"task_id": "HumanEval/14", "completion": "\n    return [string[:i] for i in range(1, len(string) + 1)]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.5104s", "mean_test_time": "2.6781s"}}
{"task_id": "HumanEval/15", "completion": "\n    return ' '.join([str(i) for i in range(n+1)])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.5072s", "mean_test_time": "2.6872s"}}
{"task_id": "HumanEval/16", "completion": "\n    return len(set(string.lower()))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.3630s", "mean_test_time": "2.9928s"}}
{"task_id": "HumanEval/17", "completion": "\n    music_list = []\n    notes = music_string.split()\n\n    for note in notes:\n        if note == 'o':\n            music_list.append(4)\n        elif note == 'o|':\n            music_list.append(2)\n        elif note == '.|':\n        \tmusic_list.append(1)\n\n    return music_list\n", "stats": {"num_rollouts": 4, "num_generations": 2, "eval_time": "16.9878s", "mean_test_time": "3.0026s"}}
{"task_id": "HumanEval/18", "completion": "\n    count = start = 0\n    while True:\n        start = string.find(substring, start) + 1\n        if start > 0:\n            count += 1\n        else:\n            return count\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.9585s", "mean_test_time": "2.8056s"}}
{"task_id": "HumanEval/19", "completion": "\n    num_dict = {\n        \"zero\": 0,\n        \"one\": 1,\n        \"two\": 2,\n        \"three\": 3,\n        \"four\": 4,\n        \"five\": 5,\n        \"six\": 6,\n        \"seven\": 7,\n        \"eight\": 8,\n        \"nine\": 9\n    }\n\n    words = numbers.split()\n    sorted_words = sorted(words, key=lambda x: num_dict[x])\n    \n    return ' '.join(sorted_words)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.3572s", "mean_test_time": "3.0746s"}}
{"task_id": "HumanEval/20", "completion": "\n    numbers = sorted(numbers)\n    smallest_difference = float('inf')\n    result = ()\n\n    for idx in range(1, len(numbers)):\n        difference = abs(numbers[idx] - numbers[idx-1])\n        \n        if difference < smallest_difference:\n            smallest_difference = difference\n            result = (numbers[idx-1], numbers[idx])\n            \n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.9420s", "mean_test_time": "2.9830s"}}
{"task_id": "HumanEval/21", "completion": "\n    min_val = min(numbers)\n    max_val = max(numbers)\n    range_val = max_val - min_val\n\n    return [(x-min_val)/range_val for x in numbers]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.7467s", "mean_test_time": "3.0470s"}}
{"task_id": "HumanEval/22", "completion": "\n    return [value for value in values if isinstance(value, int)]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.3920s", "mean_test_time": "2.6094s"}}
{"task_id": "HumanEval/23", "completion": "\n    return len(string)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "3.7145s", "mean_test_time": "2.6882s"}}
{"task_id": "HumanEval/24", "completion": "\n    for i in range(n-1, 0, -1):\n        if n % i == 0:\n            return i\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.0982s", "mean_test_time": "3.0261s"}}
{"task_id": "HumanEval/25", "completion": "\n    factors = []\n    divisor = 2\n\n    while n > 1:\n        if n % divisor == 0:\n            factors.append(divisor)\n            n //= divisor\n        else:\n            divisor += 1\n\n    return factors\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.8223s", "mean_test_time": "3.8996s"}}
{"task_id": "HumanEval/27", "completion": "\n    return ''.join([char.upper() if char.islower() else char.lower() for char in string])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.7049s", "mean_test_time": "2.6416s"}}
{"task_id": "HumanEval/28", "completion": "\n    return \"\".join(strings)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.0119s", "mean_test_time": "2.7369s"}}
{"task_id": "HumanEval/29", "completion": "\n    return [s for s in strings if s.startswith(prefix)]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.2956s", "mean_test_time": "2.4640s"}}
{"task_id": "HumanEval/30", "completion": "\n    return [n for n in l if n > 0]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.6381s", "mean_test_time": "2.8193s"}}
{"task_id": "HumanEval/31", "completion": "\n    if n < 2:\n        return False\n    for i in range(2, int(n ** 0.5) + 1):\n        if n % i == 0:\n            return False\n    return True\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.3856s", "mean_test_time": "6.1230s"}}
{"task_id": "HumanEval/34", "completion": "\n    return sorted(set(l))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "3.4399s", "mean_test_time": "2.1631s"}}
{"task_id": "HumanEval/35", "completion": "\n    return max(l)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "3.7577s", "mean_test_time": "2.4350s"}}
{"task_id": "HumanEval/36", "completion": "\n    count = 0\n    for i in range(1, n):\n        if (i % 11 == 0 or i % 13 == 0):\n            count += str(i).count('7')\n    return count\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.2609s", "mean_test_time": "3.9043s"}}
{"task_id": "HumanEval/37", "completion": "\n    even_indicies = [i for i in range(0, len(l), 2)]\n    sorted_even_values = sorted([l[i] for i in even_indicies])\n\n    result = l.copy()\n    for idx, value in zip(even_indicies, sorted_even_values):\n        result[idx] = value\n\n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.7809s", "mean_test_time": "2.6965s"}}
{"task_id": "HumanEval/39", "completion": "\n    def is_prime(num):\n        if num < 2:\n            return False\n        for i in range(2, int(num ** 0.5) + 1):\n            if num % i == 0:\n                return False\n        return True\n\n    def fibonacci(n):\n        a, b = 0, 1\n        for _ in range(n - 1):\n            a, b = b, a + b\n        return b\n\n    count = 0\n    i = 1\n    while count < n:\n        if is_prime(fibonacci(i)):\n            count += 1\n        i += 1\n\n    return fibonacci(i - 1)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "12.8134s", "mean_test_time": "4.3234s"}}
{"task_id": "HumanEval/40", "completion": "\n    l.sort()\n    for i in range(len(l) - 2):\n        left = i + 1\n        right = len(l) - 1\n        while left < right:\n            current_sum = l[i] + l[left] + l[right]\n            if current_sum < 0:\n                left += 1\n            elif current_sum > 0:\n                right -= 1\n            else:\n                return True\n    return False\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.4188s", "mean_test_time": "4.0386s"}}
{"task_id": "HumanEval/41", "completion": "\n    return n * n  # Each car from left to right will collide with each car from right to left.\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.5926s", "mean_test_time": "3.0869s"}}
{"task_id": "HumanEval/42", "completion": "\n    return [i+1 for i in l]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.3554s", "mean_test_time": "2.6405s"}}
{"task_id": "HumanEval/43", "completion": "\n    seen = set()\n    for num in l:\n        if -num in seen:\n            return True\n        else:\n            seen.add(num)\n    return False\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.2889s", "mean_test_time": "4.0348s"}}
{"task_id": "HumanEval/45", "completion": "\n    return (0.5 * a * h)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "3.8879s", "mean_test_time": "2.6320s"}}
{"task_id": "HumanEval/47", "completion": "\n    l = sorted(l)\n    length = len(l)\n\n    if length % 2 == 0:\n        return (l[length // 2 - 1] + l[length // 2]) / 2.0\n    else:\n        return l[length // 2]\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.8616s", "mean_test_time": "2.9672s"}}
{"task_id": "HumanEval/48", "completion": "\n    return text == text[::-1]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.9829s", "mean_test_time": "3.5846s"}}
{"task_id": "HumanEval/49", "completion": "\n    return pow(2, n, p)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.2850s", "mean_test_time": "3.5714s"}}
{"task_id": "HumanEval/51", "completion": "\n    vowels = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U'}\n    return \"\".join([c for c in text if c not in vowels])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.3361s", "mean_test_time": "3.6336s"}}
{"task_id": "HumanEval/52", "completion": "\n    for elem in l:\n        if elem >= t:\n            return False\n            \n    return True\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.2844s", "mean_test_time": "3.2085s"}}
{"task_id": "HumanEval/55", "completion": "\n    if n <= 0:\n        return \"Input should be positive integer.\"\n    elif n == 1:\n        return 1\n    elif n == 2:\n        return 1\n    else:\n        a = 1\n        b = 1\n        for _ in range(n - 2):\n            a, b = b, a + b\n        return b\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.5237s", "mean_test_time": "3.0258s"}}
{"task_id": "HumanEval/56", "completion": "\n    stack = []\n    for bracket in brackets:\n        if bracket == \"<\":\n            stack.append(bracket)\n        elif bracket == \">\" and len(stack) > 0:\n            stack.pop()\n        else:\n            return False\n\n    return len(stack) == 0\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.0482s", "mean_test_time": "5.7565s"}}
{"task_id": "HumanEval/57", "completion": "\n    if len(l) < 2:\n        return True\n\n    increasing = None\n\n    for idx in range(len(l)-1):\n        if l[idx] == l[idx+1]:\n            continue\n        elif l[idx] < l[idx+1]:\n            if increasing is not None and not increasing:\n                return False\n            increasing = True\n        else:\n            if increasing is not None and increasing:\n                return False\n            increasing = False\n\n    return True\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.8537s", "mean_test_time": "3.7853s"}}
{"task_id": "HumanEval/58", "completion": "\n    return sorted(list(set(l1) & set(l2)))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.8276s", "mean_test_time": "2.8356s"}}
{"task_id": "HumanEval/59", "completion": "\n    def is_prime(num):\n        if num < 2:\n            return False\n        for i in range(2, int(num ** 0.5) + 1):\n            if num % i == 0:\n                return False\n        return True\n\n    largest = 2\n    while n % 2 == 0:\n        n = n // 2\n    for i in range(3, int(n**0.5)+1, 2):\n        while n % i == 0:\n            if is_prime(i):\n                largest = i\n            n = n // i\n    if n > 2 and is_prime(n):\n        largest = n\n    return largest\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.0315s", "mean_test_time": "3.0616s"}}
{"task_id": "HumanEval/60", "completion": "\n    return n * (n + 1) // 2\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.7247s", "mean_test_time": "2.9544s"}}
{"task_id": "HumanEval/61", "completion": "\n    count = 0\n    for bracket in brackets:\n        if bracket == \"(\":\n            count += 1\n        elif bracket == \")\":\n            count -= 1\n        if count < 0:  # If we encounter a closing bracket without an opening one, return False.\n            return False\n    return count == 0  # Return True only if all brackets are properly closed.\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.8255s", "mean_test_time": "5.8197s"}}
{"task_id": "HumanEval/62", "completion": "\n    return [i * xs[i] for i in range(1, len(xs))]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.0138s", "mean_test_time": "2.9324s"}}
{"task_id": "HumanEval/63", "completion": "\n    if n == 0: return 0\n    elif n == 1: return 0\n    elif n == 2: return 1\n\n    a, b, c = 0, 0, 1\n    for _ in range(n - 2):\n        a, b, c = b, c, a + b + c\n\n    return c\n", "stats": {"num_rollouts": 7, "num_generations": 2, "eval_time": "16.7148s", "mean_test_time": "3.5126s"}}
{"task_id": "HumanEval/64", "completion": "\n    s = s.lower()\n    count = 0\n    for char in s:\n        if char in 'aeiou':\n            count += 1\n    if len(s) > 0 and s[-1] == 'y':\n        count += 1\n    return count\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.7918s", "mean_test_time": "3.7716s"}}
{"task_id": "HumanEval/65", "completion": "\n    digits = list(str(x))\n    if shift > len(digits):\n        return ''.join(reversed(digits))\n    else:\n        return ''.join(digits[-shift:] + digits[:-shift])\n\n", "stats": {"num_rollouts": 3, "num_generations": 2, "eval_time": "11.7361s", "mean_test_time": "3.0679s"}}
{"task_id": "HumanEval/66", "completion": "\n    return sum(ord(c) for c in s if c.isupper())\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.3861s", "mean_test_time": "4.3374s"}}
{"task_id": "HumanEval/69", "completion": "\n    from collections import Counter\n\n    count_dict = Counter(lst)\n\n    for num in sorted(count_dict.keys(), reverse=True):\n        if count_dict[num] >= num:\n            return num\n    \n    return -1\n\n", "stats": {"num_rollouts": 48, "num_generations": 8, "eval_time": "114.7303s", "mean_test_time": "9.8648s"}}
{"task_id": "HumanEval/70", "completion": "\n    lst.sort()\n    result = []\n    while len(lst):\n        result.append(lst.pop(0)) # append minimum value\n        if len(lst): \n            result.append(lst.pop()) # append maximum value\n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.6425s", "mean_test_time": "4.5091s"}}
{"task_id": "HumanEval/71", "completion": "\n    if a + b > c and a + c > b and b + c > a:\n        # calculate semi-perimeter\n        s = (a + b + c) / 2.0\n        # apply Heron's formula to get area\n        return round(pow(s * (s - a) * (s - b) * (s - c), 0.5) , 2)\n    else:\n        return -1\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.8491s", "mean_test_time": "4.1140s"}}
{"task_id": "HumanEval/72", "completion": "\n    def is_palindrome(lst):\n        return lst == lst[::-1]\n        \n    if not is_palindrome(q) or sum(q) > w:\n        return False\n    else:\n        return True\n\n", "stats": {"num_rollouts": 5, "num_generations": 2, "eval_time": "13.9407s", "mean_test_time": "3.2267s"}}
{"task_id": "HumanEval/73", "completion": "\n    def count_changes(arr):\n        n = len(arr)\n        changes = 0\n        for i in range(n//2):\n            if arr[i] != arr[n-i-1]:\n                changes += 1\n        return changes\n\n    return count_changes(arr)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.4025s", "mean_test_time": "3.9492s"}}
{"task_id": "HumanEval/74", "completion": "\ndef total_match(lst1, lst2):\n    sum1 = sum([len(i) for i in lst1])\n    sum2 = sum([len(i) for i in lst2])\n    if sum1 < sum2:\n        return lst1\n    elif sum1 > sum2:\n        return lst2\n    else:\n        return lst1\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.3271s", "mean_test_time": "5.4852s"}}
{"task_id": "HumanEval/75", "completion": "\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n\n    factors = []\n    for i in range(2, a+1):\n        while a % i == 0 and is_prime(i):\n            factors.append(i)\n            a //= i\n            if len(factors) > 3:\n                break\n\n    return len(factors) == 3\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.4797s", "mean_test_time": "4.6215s"}}
{"task_id": "HumanEval/76", "completion": "\n    if n == 1 and x != 1:\n        return False\n\n    i = 0\n    while True:\n        temp = n ** i\n        if temp == x:\n            return True\n        elif temp > x or (n == 1 and x > 1):\n            return False\n        else:\n            i += 1\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.1601s", "mean_test_time": "4.4751s"}}
{"task_id": "HumanEval/77", "completion": "\n    a = abs(a)  # We take the absolute value to handle negative numbers.\n    return int(round(a ** (1./3))) ** 3 == a\n\n", "stats": {"num_rollouts": 8, "num_generations": 2, "eval_time": "14.0921s", "mean_test_time": "3.8392s"}}
{"task_id": "HumanEval/78", "completion": "\n    prime_hex_digits = {'2', '3', '5', '7', 'B', 'D'}\n    return sum(1 for c in num if c in prime_hex_digits)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.0788s", "mean_test_time": "3.5220s"}}
{"task_id": "HumanEval/79", "completion": "\n    binary = bin(decimal)[2:]  # remove '0b' from the start of the string\n    return f\"db{binary}db\"\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.8654s", "mean_test_time": "2.9201s"}}
{"task_id": "HumanEval/80", "completion": "\n    if len(s) < 3:\n        return False\n\n    for i in range(len(s)-2):\n        if s[i] == s[i+1] or s[i+1] == s[i+2] or s[i] == s[i+2]:\n            return False\n\n    return True\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.5107s", "mean_test_time": "3.8800s"}}
{"task_id": "HumanEval/81", "completion": "\ndef numerical_letter_grade(grades):\n    result = []\n    for grade in grades:\n        if grade == 4.0:\n            result.append('A+')\n        elif grade > 3.7:\n            result.append('A')\n        elif grade > 3.3:\n            result.append('A-')\n        elif grade > 3.0:\n            result.append('B+')\n        elif grade > 2.7:\n            result.append('B')\n        elif grade > 2.3:\n            result.append('B-')\n        elif grade > 2.0:\n            result.append('C+')\n        elif grade > 1.7:\n            result.append('C')\n        elif grade > 1.3:\n            result.append('C-')\n        elif grade > 1.0:\n            result.append('D+')\n        elif grade > 0.7:\n            result.append('D')\n        elif grade > 0.0:\n            result.append('D-')\n        else:\n            result.append('E')\n    return result\n", "stats": {"num_rollouts": 65, "num_generations": 18, "eval_time": "251.1175s", "mean_test_time": "3.5469s"}}
{"task_id": "HumanEval/82", "completion": "\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n ** 0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n\n    return is_prime(len(string))\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.9127s", "mean_test_time": "6.8776s"}}
{"task_id": "HumanEval/84", "completion": "\n    return bin(sum([int(i) for i in str(N)]))[2:]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.8600s", "mean_test_time": "3.4684s"}}
{"task_id": "HumanEval/86", "completion": "\n    words = s.split()\n    result = []\n\n    for word in words:\n        new_word = \"\".join(sorted(word))\n        result.append(new_word)\n\n    return \" \".join(result)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.6043s", "mean_test_time": "3.8166s"}}
{"task_id": "HumanEval/88", "completion": "\n    if not array:\n        return []\n\n    sum_first_last = array[0] + array[-1]\n\n    if sum_first_last % 2 == 0:\n        # descending order\n        return sorted(array, reverse=True)\n    else:\n        # ascending order\n        return sorted(array)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.4797s", "mean_test_time": "4.2317s"}}
{"task_id": "HumanEval/89", "completion": "\n    result = []\n    for c in s:\n        if 'a' <= c <= 'z':\n            result.append(chr((ord(c) - ord('a') + 2*2) % 26 + ord('a')))\n        elif 'A' <= c <= 'Z':\n            result.append(chr((ord(c) - ord('A') + 2*2) % 26 + ord('A')))\n    return \"\".join(result)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.1601s", "mean_test_time": "3.9432s"}}
{"task_id": "HumanEval/90", "completion": "\n    if len(lst) < 2:\n        return None\n\n    smallest = float('inf')\n    second_smallest = float('inf')\n\n    for num in lst:\n        if num < smallest:\n            second_smallest = smallest\n            smallest = num\n        elif smallest < num < second_smallest:\n            second_smallest = num\n\n    return None if second_smallest == float('inf') else second_smallest\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.7654s", "mean_test_time": "3.8610s"}}
{"task_id": "HumanEval/92", "completion": "\ndef any_int(x, y, z):\n    if isinstance(x, int) and isinstance(y, int) and isinstance(z, int):\n        return x == y + z or y == x + z or z == x + y\n    else:\n        return False\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.7537s", "mean_test_time": "4.4051s"}}
{"task_id": "HumanEval/94", "completion": "\n    def is_prime(n):\n        if n < 2: return False\n        for i in range(2, int(n**0.5) + 1):\n            if n % i == 0: return False\n        return True\n\n    primes = [i for i in lst if is_prime(i)]\n    largest_prime = max(primes)\n    \n    return sum([int(digit) for digit in str(largest_prime)])\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.4342s", "mean_test_time": "4.2470s"}}
{"task_id": "HumanEval/96", "completion": "\n    def is_prime(num):\n        if num < 2:\n            return False\n        for i in range(2, int(num ** 0.5) + 1):\n            if num % i == 0:\n                return False\n        return True\n\n    primes = [x for x in range(n) if is_prime(x)]\n    return primes\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.7585s", "mean_test_time": "4.4683s"}}
{"task_id": "HumanEval/98", "completion": "\n    vowels = 'AEIOU'\n    return sum(s[i] in vowels for i in range(0, len(s), 2))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.3243s", "mean_test_time": "3.8308s"}}
{"task_id": "HumanEval/99", "completion": "\n    import math\n\n    value = float(value)\n    if value > 0:\n        return int(math.floor(value + 0.5))\n    else:\n        return int(math.ceil(value - 0.5))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.8308s", "mean_test_time": "2.9352s"}}
{"task_id": "HumanEval/100", "completion": "\n    result = [n]\n    next_stone = n + 2 if n % 2 == 0 else n + 2\n\n    for _ in range(1, n):\n        result.append(next_stone)\n        next_stone += 2\n\n    return result\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.2290s", "mean_test_time": "3.2458s"}}
{"task_id": "HumanEval/101", "completion": "\n    return s.replace(',', '').split()\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.6417s", "mean_test_time": "3.8811s"}}
{"task_id": "HumanEval/102", "completion": "\n    for i in range(y, x-1, -1):\n        if i % 2 == 0:\n            return i\n    return -1\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.4492s", "mean_test_time": "3.8352s"}}
{"task_id": "HumanEval/104", "completion": "\n    def has_even(n):\n        return any(int(d) % 2 == 0 for d in str(n))\n\n    return sorted([x for x in x if not has_even(x)])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.5496s", "mean_test_time": "3.0871s"}}
{"task_id": "HumanEval/105", "completion": "\n    num2words = {1: 'One', 2: 'Two', 3: 'Three', 4: 'Four', 5: 'Five', 6: 'Six', 7: 'Seven', 8: 'Eight', 9: 'Nine'}\n    words2num = {v: k for k, v in num2words.items()}\n    \n    arr = sorted([i for i in arr if 1 <= i <= 9])[::-1]\n        \n    return [num2words[i] for i in arr]\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.6024s", "mean_test_time": "3.5220s"}}
{"task_id": "HumanEval/106", "completion": "\n    def factorial(n):\n        if n == 0 or n == 1:\n            return 1\n        else:\n            return n * factorial(n - 1)\n\n    def sum_to_n(n):\n        return (n*(n+1))//2\n\n    result = []\n    for i in range(1, n + 1):\n        if i % 2 == 0:\n            result.append(factorial(i))\n        else:\n            result.append(sum_to_n(i))\n\n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.8305s", "mean_test_time": "2.8582s"}}
{"task_id": "HumanEval/107", "completion": "\n    def is_palindrome(num):\n        return str(num) == str(num)[::-1]\n\n    count_even = 0\n    count_odd = 0\n\n    for i in range(1, n+1):\n        if is_palindrome(i):\n            if i % 2 == 0:\n                count_even += 1\n            else:\n                count_odd += 1\n                \n    return (count_even, count_odd)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.6271s", "mean_test_time": "3.9079s"}}
{"task_id": "HumanEval/109", "completion": "\n    def check_sort(arr):\n        return all(arr[i] <= arr[i + 1] for i in range(len(arr) - 1))\n\n    if len(arr) == 0 or check_sort(arr):\n        return True\n    \n    shifted = arr[-1:] + arr[:-1]\n    while shifted != arr:\n        if check_sort(shifted):\n            return True\n        shifted = shifted[-1:] + shifted[:-1]\n        \n    return False\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.6707s", "mean_test_time": "2.9742s"}}
{"task_id": "HumanEval/110", "completion": "\n    odd_lst1 = sum(x % 2 != 0 for x in lst1)\n    even_lst2 = sum(x % 2 == 0 for x in lst2)\n\n    if odd_lst1 <= even_lst2:\n        return \"YES\"\n    else:\n        return \"NO\"\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.6684s", "mean_test_time": "3.4722s"}}
{"task_id": "HumanEval/111", "completion": "\n    count_dict = {}\n    for letter in test.split():\n        if letter not in count_dict:\n            count_dict[letter] = 1\n        else:\n            count_dict[letter] += 1\n            \n    max_value = max(count_dict.values()) if count_dict else 0\n    \n    return {k: v for k, v in count_dict.items() if v == max_value}\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.7701s", "mean_test_time": "3.8461s"}}
{"task_id": "HumanEval/112", "completion": "\n    for ch in c:\n        s = s.replace(ch, '')\n        \n    return (s, s == s[::-1])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.1626s", "mean_test_time": "4.1764s"}}
{"task_id": "HumanEval/114", "completion": "\n    current_sum = nums[0]\n    min_sum = nums[0]\n\n    for num in nums[1:]:\n        current_sum = min(current_sum + num, num)\n        min_sum = min(min_sum, current_sum)\n        \n    return min_sum\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.0547s", "mean_test_time": "5.7426s"}}
{"task_id": "HumanEval/116", "completion": "\n    return sorted(arr, key=lambda x: (bin(x).count('1'), x))\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.8061s", "mean_test_time": "4.3596s"}}
{"task_id": "HumanEval/117", "completion": "\n    def count_consonants(word):\n        return sum([1 for c in word if c.lower() in 'bcdfghjklmnpqrstvwxyz'])\n\n    words = s.split(' ')\n    return [word for word in words if count_consonants(word) == n]\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.5278s", "mean_test_time": "3.5369s"}}
{"task_id": "HumanEval/118", "completion": "\n    vowels = 'aeiouAEIOU'\n    word = word[::-1]  # reverse the string\n\n    for i in range(1, len(word) - 1):\n        if word[i] in vowels and word[i - 1] not in vowels and word[i + 1] not in vowels:\n            return word[i]\n\n    return ''\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "12.0871s", "mean_test_time": "6.5269s"}}
{"task_id": "HumanEval/120", "completion": "\n    arr.sort(reverse=True)\n    return sorted(arr[:k])\n\n", "stats": {"num_rollouts": 19, "num_generations": 5, "eval_time": "38.2714s", "mean_test_time": "5.6303s"}}
{"task_id": "HumanEval/121", "completion": "\n    return sum(x for i, x in enumerate(lst) if i % 2 == 0 and x % 2 != 0)\n\n", "stats": {"num_rollouts": 10, "num_generations": 2, "eval_time": "12.9046s", "mean_test_time": "3.5772s"}}
{"task_id": "HumanEval/122", "completion": "\n    return sum([num for num in arr[:k] if len(str(abs(num))) <= 2])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "5.3153s", "mean_test_time": "2.9553s"}}
{"task_id": "HumanEval/123", "completion": "\n    def collatz(n):\n        result = []\n        while n != 1:\n            if n % 2 == 0:\n                n /= 2\n            else:\n                result.append(int(n))\n                n = 3 * n + 1\n        return [1] + result[::-1]\n    \n    collatz_sequence = collatz(n)\n    odd_numbers = list(filter(lambda x: x % 2 != 0, collatz_sequence))\n    return sorted(list(set(odd_numbers)))\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.3680s", "mean_test_time": "2.7558s"}}
{"task_id": "HumanEval/124", "completion": "\n    import re\n\n    if not date or len(date) != 10 or date[2] != '-' or date[5] != '-':\n        return False\n\n    month, day, year = map(int, date.split('-'))\n\n    if month < 1 or month > 12:\n        return False\n\n    if month in [4, 6, 9, 11]:\n        if day < 1 or day > 30:\n            return False\n    elif month == 2:\n        if day < 1 or day > 29:\n            return False\n    else:\n        if day < 1 or day > 31:\n            return False\n\n    return True\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "16.3543s", "mean_test_time": "6.8136s"}}
{"task_id": "HumanEval/131", "completion": "\n    product = 1\n    for digit in str(n):\n        if int(digit) % 2 != 0:\n            product *= int(digit)\n    return product if any(int(digit) % 2 != 0 for digit in str(n)) else 0\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.3552s", "mean_test_time": "3.4790s"}}
{"task_id": "HumanEval/133", "completion": "\n    import math\n    return sum([math.ceil(i)**2 for i in lst])\n\n", "stats": {"num_rollouts": 16, "num_generations": 3, "eval_time": "25.8381s", "mean_test_time": "5.8763s"}}
{"task_id": "HumanEval/135", "completion": "\n    for i in range(len(arr) - 1, 0, -1):\n        if arr[i] < arr[i-1]:\n            return i\n    return -1\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.0402s", "mean_test_time": "2.9933s"}}
{"task_id": "HumanEval/136", "completion": "\n    negatives = [x for x in lst if x < 0]\n    positives = [x for x in lst if x > 0]\n\n    return (max(negatives) if negatives else None, min(positives) if positives else None)\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.9730s", "mean_test_time": "5.8576s"}}
{"task_id": "HumanEval/139", "completion": "\n    def factorial(n):\n        if n == 0 or n == 1:\n            return 1\n        else:\n            return n * factorial(n - 1)\n\n    result = 1\n    for i in range(n, 0, -1):\n        result *= factorial(i)\n\n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.3532s", "mean_test_time": "2.8684s"}}
{"task_id": "HumanEval/143", "completion": "\n    def is_prime(n):\n        if n < 2:\n            return False\n        for i in range(2, int(n ** 0.5) + 1):\n            if n % i == 0:\n                return False\n        return True\n\n    words = sentence.split()\n    result = [word for word in words if is_prime(len(word))]\n    \n    return \" \".join(result)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.3655s", "mean_test_time": "3.5629s"}}
{"task_id": "HumanEval/146", "completion": "\n    def check_digits(num):\n        if num < 0:\n            num = -num\n        \n        str_num = str(num)\n        return int(str_num[0]) % 2 == 1 and int(str_num[-1]) % 2 == 1\n    \n    count = 0\n    for num in nums:\n        if num > 10 and check_digits(num):\n            count += 1\n            \n    return count\n", "stats": {"num_rollouts": 2, "num_generations": 2, "eval_time": "16.9521s", "mean_test_time": "3.5250s"}}
{"task_id": "HumanEval/148", "completion": "\ndef bf(planet1, planet2):\n    planets = [\"Mercury\", \"Venus\", \"Earth\", \"Mars\", \n               \"Jupiter\", \"Saturn\", \"Uranus\", \"Neptune\"]\n    \n    if (planet1 not in planets) or (planet2 not in planets):\n        return ()\n        \n    start = min(planets.index(planet1), planets.index(planet2))\n    end = max(planets.index(planet1), planets.index(planet2))\n    \n    return tuple(planets[start+1:end])\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "11.9114s", "mean_test_time": "3.5809s"}}
{"task_id": "HumanEval/149", "completion": "\n    lst = [i for i in lst if len(i) % 2 == 0]\n    return sorted(sorted(lst), key=len)\n\n", "stats": {"num_rollouts": 7, "num_generations": 3, "eval_time": "22.5690s", "mean_test_time": "3.5755s"}}
{"task_id": "HumanEval/150", "completion": "\ndef is_prime(n):\n    if n <= 1 or (n % 2 == 0 and n > 2): \n        return False\n    for i in range(3, int(n**0.5) + 1, 2):\n        if n % i == 0:\n            return False\n    return True\n\ndef x_or_y(n, x, y):\n    if is_prime(n):\n        return x\n    else:\n        return y\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.2616s", "mean_test_time": "4.3853s"}}
{"task_id": "HumanEval/152", "completion": "\ndef compare(game, guess):\n    return [abs(g-c) for c, g in zip(game, guess)]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.1641s", "mean_test_time": "3.0391s"}}
{"task_id": "HumanEval/153", "completion": "\n    def get_strength(extension):\n        cap = sum(1 for c in extension if c.isupper())\n        sm = sum(1 for c in extension if c.islower())\n        return cap - sm\n\n    strongest_ext = max(extensions, key=get_strength)\n    return f\"{class_name}.{strongest_ext}\"\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "10.1006s", "mean_test_time": "4.1725s"}}
{"task_id": "HumanEval/154", "completion": "\n    def rotate(s):\n        return s[-1] + s[:-1]\n\n    b = b.strip()\n    for _ in range(len(b)):\n        if b in a or b[::-1] in a:\n            return True\n        else:\n            b = rotate(b)\n            \n    return False\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.0502s", "mean_test_time": "3.2859s"}}
{"task_id": "HumanEval/155", "completion": "\n    num = abs(num)\n    evens = 0\n    odds = 0\n\n    for digit in str(num):\n        if int(digit) % 2 == 0:\n            evens += 1\n        else:\n            odds += 1\n\n    return (evens, odds)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.1421s", "mean_test_time": "4.2304s"}}
{"task_id": "HumanEval/156", "completion": "\n    roman = {1000:'m', 900:'cm', 500:'d', 400:'cd', 100:'c', 90:'xc',\n             50:'l',  40:'xl', 10:'x',   9:'ix',  5:'v',  4:'iv', 1:'i'}\n    \n    result = ''\n    for key in sorted(roman.keys(), reverse=True):\n        while number >= key:\n            result += roman[key]\n            number -= key\n            \n    return result\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "14.0442s", "mean_test_time": "6.7127s"}}
{"task_id": "HumanEval/157", "completion": "\n    sides = sorted([a, b, c])\n    return sides[0]**2 + sides[1]**2 == sides[2]**2\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.3412s", "mean_test_time": "5.6877s"}}
{"task_id": "HumanEval/158", "completion": "\n    def unique_characters(word):\n        return len(set(word))\n\n    max_unique = max([unique_characters(w) for w in words])\n    candidates = [w for w in words if unique_characters(w) == max_unique]\n    \n    return min(candidates)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "9.0399s", "mean_test_time": "4.5135s"}}
{"task_id": "HumanEval/159", "completion": "\n    if need > remaining:\n        return [number + remaining, 0]\n    else:\n        return [number + need, remaining - need]\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.7135s", "mean_test_time": "3.8704s"}}
{"task_id": "HumanEval/161", "completion": "\n    if not any(char.isalpha() for char in s):\n        return s[::-1]\n        \n    return ''.join([char.upper() if char.islower() else char.lower() for char in s])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.4080s", "mean_test_time": "3.8841s"}}
{"task_id": "HumanEval/162", "completion": "\n    import hashlib\n\n    if text is None or len(text.strip()) == 0:\n        return None\n\n    hasher = hashlib.md5()\n    hasher.update(text.encode('utf-8'))\n\n    return hasher.hexdigest()\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "6.8594s", "mean_test_time": "2.9742s"}}
{"task_id": "HumanEval/26", "completion": "\n    result = []\n    counts = {}\n\n    for num in numbers:\n        if num not in counts:\n            counts[num] = 0\n        else:\n            counts[num] += 1\n\n    for num, count in counts.items():\n        if count == 0:\n            result.append(num)\n\n    return result\n", "stats": {"num_rollouts": 12, "num_generations": 2, "eval_time": "16.2475s", "mean_test_time": "2.7077s"}}
{"task_id": "HumanEval/33", "completion": "\n    divisible_by_three = [l[i] for i in range(len(l)) if i % 3 == 0]\n    sorted_divisible_by_three = sorted(divisible_by_three)\n\n    result = l.copy()\n    for i, value in enumerate(result):\n        if i % 3 == 0:\n            result[i] = sorted_divisible_by_three.pop(0)\n    \n    return result\n", "stats": {"num_rollouts": 77, "num_generations": 15, "eval_time": "155.0651s", "mean_test_time": "4.1666s"}}
{"task_id": "HumanEval/46", "completion": "\n    fib_sequence = [0, 0, 2, 0] + [0] * (n - 3)\n\n    for i in range(3, n):\n        fib_sequence[i + 1] = fib_sequence[i] + fib_sequence[i - 1] + fib_sequence[i - 2] + fib_sequence[i - 3]\n\n    return fib_sequence[-1]\n", "stats": {"num_rollouts": 5, "num_generations": 2, "eval_time": "18.6960s", "mean_test_time": "2.8343s"}}
{"task_id": "HumanEval/54", "completion": "\n    return set(s0) == set(s1)\n\n", "stats": {"num_rollouts": 42, "num_generations": 10, "eval_time": "58.7350s", "mean_test_time": "3.5356s"}}
{"task_id": "HumanEval/67", "completion": "\n    apples = int(s.split('apples')[0].strip())\n    oranges = int(s.split('and ')[1].split('oranges')[0].strip())\n\n    return n - apples - oranges\n\n", "stats": {"num_rollouts": 10, "num_generations": 4, "eval_time": "26.3355s", "mean_test_time": "3.5756s"}}
{"task_id": "HumanEval/68", "completion": "\n    smallest_even = [float('inf'), -1]\n    for idx, num in enumerate(arr):\n        if num % 2 == 0 and num < smallest_even[0]:\n            smallest_even = [num, idx]\n            \n    return smallest_even if smallest_even[1] >= 0 else []\n", "stats": {"num_rollouts": 3, "num_generations": 2, "eval_time": "17.7257s", "mean_test_time": "4.4516s"}}
{"task_id": "HumanEval/83", "completion": "\n    return 2 * (9 * (10 ** (n - 2))) if n > 1 else 1\n\n", "stats": {"num_rollouts": 68, "num_generations": 18, "eval_time": "102.5965s", "mean_test_time": "3.5412s"}}
{"task_id": "HumanEval/85", "completion": "\n    sum = 0\n    for i in range(len(lst)):\n        if lst[i] % 2 == 0 and i % 2 != 0:\n            sum += lst[i]\n    return sum\n\n", "stats": {"num_rollouts": 41, "num_generations": 7, "eval_time": "34.6849s", "mean_test_time": "2.8075s"}}
{"task_id": "HumanEval/91", "completion": "\n    sentences = S.split('.')\n    sentences += S.split('?')\n    sentences += S.split('s')\n    return sum(sentence.strip().startswith(\"I\") for sentence in sentences)\n\n", "stats": {"num_rollouts": 128, "num_generations": 17, "eval_time": "122.5987s", "mean_test_time": "3.5415s"}}
{"task_id": "HumanEval/93", "completion": "\n    def replace_vowels(c):\n        if c in 'aeiouAEIOU':\n            return chr((ord(c) - 97 + 2) % 26 + 97) if c.islower() else chr((ord(c) - 65 + 2) % 26 + 65)\n        return c\n    \n    return ''.join([replace_vowels(c).swapcase() for c in message])\n", "stats": {"num_rollouts": 19, "num_generations": 6, "eval_time": "64.2410s", "mean_test_time": "3.0224s"}}
{"task_id": "HumanEval/95", "completion": "\n    if not dict:\n        return False\n\n    lower = 0\n    upper = 0\n\n    for key in dict:\n        if isinstance(key, str):\n            if key == key.lower():\n                lower += 1\n            elif key == key.upper():\n                upper += 1\n        else:\n            return False\n\n    return lower == len(dict) or upper == len(dict)\n", "stats": {"num_rollouts": 27, "num_generations": 7, "eval_time": "57.5459s", "mean_test_time": "3.5707s"}}
{"task_id": "HumanEval/97", "completion": "\n    return (a % 10) * (b % 10)\n\n", "stats": {"num_rollouts": 11, "num_generations": 3, "eval_time": "20.6902s", "mean_test_time": "3.7876s"}}
{"task_id": "HumanEval/103", "completion": "\n    if n > m:\n        return -1\n\n    avg = (n + m) / 2\n    rounded_avg = round(avg)\n\n    binary = bin(rounded_avg)[2:]\n\n    return \"0b\" + binary\n", "stats": {"num_rollouts": 68, "num_generations": 8, "eval_time": "79.5943s", "mean_test_time": "5.8784s"}}
{"task_id": "HumanEval/108", "completion": "\n    def sum_digits(n):\n        if n < 0:\n            n = -n\n            return sum(map(int, str(n)[1:]))\n        else:\n            return sum(map(int, str(n)))\n\n    count = 0\n    for num in arr:\n        if sum_digits(num) > 0:\n            count += 1\n\n    return count\n", "stats": {"num_rollouts": 82, "num_generations": 14, "eval_time": "130.9459s", "mean_test_time": "4.7888s"}}
{"task_id": "HumanEval/115", "completion": "\n    rows, cols = len(grid), len(grid[0])\n    bucket_count = 0\n\n    for row in grid:\n        bucket_count += sum(row)\n\n    return math.ceil(bucket_count / capacity)\n\n", "stats": {"num_rollouts": 128, "num_generations": 21, "eval_time": "191.4450s", "mean_test_time": "3.9762s"}}
{"task_id": "HumanEval/119", "completion": "\n    def is_good(s):\n        count = 0\n        for c in s:\n            if c == '(':\n                count += 1\n            else:\n                if count == 0:\n                    return False\n                count -= 1\n        return count == 0\n\n    lst.sort()  # sort the list to ensure that we concatenate smaller strings first\n    s = lst[0] + lst[1]\n    while not is_good(s):\n        if len(lst) < 2:\n            return 'No'\n        lst.append(lst.pop(0) + lst.pop(0))  # append the concatenation of two smallest strings to the end of list\n        s = ''.join(lst)\n    return 'Yes'\n", "stats": {"num_rollouts": 2, "num_generations": 2, "eval_time": "26.1444s", "mean_test_time": "5.8154s"}}
{"task_id": "HumanEval/125", "completion": "\n    import re\n\n    if ' ' in txt:\n        return txt.split(' ')\n    elif ',' in txt:\n        return txt.split(',')\n    else:\n        count = 0\n        for c in txt:\n            if c.islower():\n                if (ord(c) - ord('a')) % 2 == 1:\n                    count += 1\n        return count\n", "stats": {"num_rollouts": 5, "num_generations": 2, "eval_time": "16.8910s", "mean_test_time": "3.8407s"}}
{"task_id": "HumanEval/126", "completion": "\n    return lst == sorted(lst) and len(set(lst)) == len(lst)\n\n", "stats": {"num_rollouts": 128, "num_generations": 21, "eval_time": "219.8920s", "mean_test_time": "6.1250s"}}
{"task_id": "HumanEval/127", "completion": "\ndef intersection(interval1, interval2):\n    max_start = max(interval1[0], interval2[0])\n    min_end = min(interval1[1], interval2[1])\n    if max_start > min_end:  # no overlap\n        return \"NO\"\n    intersection_len = min_end - max_start + 1\n    if is_prime(intersection_len):\n        return \"YES\"\n    else:\n        return \"NO\"\n\ndef is_prime(n):\n    \"\"\"Check if a number is prime.\"\"\"\n    if n < 2:\n        return False\n    for i in range(2, int(n**0.5) + 1):\n        if n % i == 0:\n            return False\n    return True\n", "stats": {"num_rollouts": 128, "num_generations": 16, "eval_time": "209.6350s", "mean_test_time": "3.8307s"}}
{"task_id": "HumanEval/128", "completion": "\n    if not arr:\n        return None\n\n    total = 0\n    sign_product = 1\n\n    for num in arr:\n        if num < 0:\n            sign_product *= -1\n        elif num > 0:\n            sign_product *= 1\n        else:\n            return 0\n\n        total += abs(num)\n\n    return total * sign_product\n", "stats": {"num_rollouts": 44, "num_generations": 6, "eval_time": "57.1338s", "mean_test_time": "4.3394s"}}
{"task_id": "HumanEval/129", "completion": "\n    import heapq\n\n    n = len(grid)\n    directions = [(0, 1), (1, 0), (-1, 0), (0, -1)]\n    visited = set()\n    min_heap = []\n    \n    for i in range(n):\n        for j in range(n):\n            if len(min_heap) < k:\n                heapq.heappush(min_heap, (grid[i][j], i * n + j))\n            else:\n                if grid[i][j] > min_heap[0][0]:\n                    heapq.heappop(min_heap)\n                    heapq.heappush(min_heap, (grid[i][j], i * n + j))\n    \n    result = []\n    while len(min_heap):\n        _, idx = heapq.heappop(min_heap)\n        result.append(idx % n + 1)\n        \n    return sorted(result)\n", "stats": {"num_rollouts": 128, "num_generations": 29, "eval_time": "545.9258s", "mean_test_time": "5.8190s"}}
{"task_id": "HumanEval/130", "completion": "\n    if n < 0:\n        return []\n\n    tri_sequence = [1, 3, 2] + [0] * (n - 2)\n\n    for i in range(3, n + 1):\n        if tri_sequence[i - 1] % 2 == 0:\n            tri_sequence[i] = 1 + tri_sequence[i - 1] // 2\n        else:\n            tri_sequence[i] = tri_sequence[i - 2] + tri_sequence[i - 1] + 3\n\n    return tri_sequence[:n+1]\n", "stats": {"num_rollouts": 128, "num_generations": 31, "eval_time": "344.9343s", "mean_test_time": "4.3706s"}}
{"task_id": "HumanEval/132", "completion": "\n    stack = []\n    for ch in string:\n        if ch == '[':\n            stack.append(ch)\n        else: # ch == ']'\n            if len(stack) == 0 or stack[-1] != '[':\n                return False\n            stack.pop()\n            \n    return len(stack) > 0\n", "stats": {"num_rollouts": 128, "num_generations": 10, "eval_time": "133.6906s", "mean_test_time": "6.2275s"}}
{"task_id": "HumanEval/134", "completion": "\n    if not txt:\n        return False\n\n    last_character = txt[-1]\n    second_to_last_character = '' if len(txt) == 1 else txt[-2]\n\n    return last_character.isalpha() and (second_to_last_character == ' ' or not second_to_last_character.isalnum())\n", "stats": {"num_rollouts": 6, "num_generations": 2, "eval_time": "19.9676s", "mean_test_time": "5.5656s"}}
{"task_id": "HumanEval/137", "completion": "\n    a = a if isinstance(a, str) else str(a).replace('.', '').replace(',', '.')\n    b = b if isinstance(b, str) else str(b).replace('.', '').replace(',', '.')\n    \n    a_type = type(a)\n    b_type = type(b)\n\n    if a_type != b_type:\n        raise TypeError(\"Both arguments must be of the same type\")\n        \n    if a_type == str:\n        a, b = float(a), float(b)\n    \n    return None if a==b else max(a, b)\n", "stats": {"num_rollouts": 128, "num_generations": 19, "eval_time": "188.5222s", "mean_test_time": "4.1138s"}}
{"task_id": "HumanEval/138", "completion": "\n    return n % 2 == 0 and n >= 8\n\n", "stats": {"num_rollouts": 68, "num_generations": 20, "eval_time": "121.0161s", "mean_test_time": "3.8373s"}}
{"task_id": "HumanEval/140", "completion": "\n    last_was_space = False\n    new_text = []\n\n    for c in text:\n        if c.isspace():\n            if last_was_space:\n                new_text[-1] = '-'\n            else:\n                new_text.append('_')\n            \n            last_was_space = True\n        else:\n            new_text.append(c)\n            last_was_space = False\n    \n    return ''.join(new_text)\n", "stats": {"num_rollouts": 128, "num_generations": 23, "eval_time": "219.4173s", "mean_test_time": "2.9928s"}}
{"task_id": "HumanEval/141", "completion": "\n    import re\n\n    if file_name.count('.') != 1:\n        return \"No\"\n\n    name, extension = file_name.split('.')\n\n    if not re.match(\"^[a-zA-Z]\", name):\n        return \"No\"\n    \n    if len(re.findall(\"\\d\", name)) > 3:\n        return \"No\"\n\n    if extension not in ['txt', 'exe', 'dll']:\n        return \"No\"\n\n    return \"Yes\"\n", "stats": {"num_rollouts": 42, "num_generations": 8, "eval_time": "141.9340s", "mean_test_time": "10.2157s"}}
{"task_id": "HumanEval/142", "completion": "\n    return sum(x**2 if i%3==0 else x**3 for i, x in enumerate(lst))\n\n", "stats": {"num_rollouts": 128, "num_generations": 22, "eval_time": "214.4558s", "mean_test_time": "5.5520s"}}
{"task_id": "HumanEval/144", "completion": "\n    x_num, x_denom = map(int, x.split('/'))\n    n_num, n_denom = map(int, n.split('/'))\n\n    return (x_num * n_num) % (x_denom * n_denom) == 0\n", "stats": {"num_rollouts": 8, "num_generations": 2, "eval_time": "23.8431s", "mean_test_time": "6.0767s"}}
{"task_id": "HumanEval/145", "completion": "\n    def sum_digits(n):\n        if n < 0:\n            n = -n\n        return sum(map(int, str(n)))\n\n    nums.sort()\n    nums.sort(key=sum_digits)\n    return nums\n", "stats": {"num_rollouts": 128, "num_generations": 21, "eval_time": "161.9065s", "mean_test_time": "3.5315s"}}
{"task_id": "HumanEval/147", "completion": "\n    a = [i * i - i + 1 for i in range(1, n+1)]\n    count = 0\n    mod_counts = [0]*3\n\n    for num in a:\n        mod_counts[num % 3] += 1\n        \n    count += mod_counts[0]*(mod_counts[0]-1)*(mod_counts[0]-2)//6\n    count += mod_counts[1]*mod_counts[2]*(mod_counts[0])\n    count += mod_counts[1]*(mod_counts[1]-1)*(mod_counts[1]-2)//6\n    count += mod_counts[2]*(mod_counts[2]-1)*(mod_counts[2]-2)//6\n    \n    return count\n", "stats": {"num_rollouts": 3, "num_generations": 2, "eval_time": "28.1606s", "mean_test_time": "2.7737s"}}
{"task_id": "HumanEval/160", "completion": "\n    expression = str(operand[0])\n\n    for idx in range(len(operator)):\n        expression += ' ' + operator[idx] + ' ' + str(operand[idx + 1])\n\n    return eval(expression)\n\n", "stats": {"num_rollouts": 6, "num_generations": 2, "eval_time": "17.9219s", "mean_test_time": "2.7864s"}}
{"task_id": "HumanEval/163", "completion": "\n    return [i for i in range(min(a, b), max(a, b)+1) if i % 2 == 0]\n\n", "stats": {"num_rollouts": 128, "num_generations": 18, "eval_time": "118.2575s", "mean_test_time": "2.9841s"}}
{"task_id": "HumanEval/32", "completion": "\n    def poly_prime(xs, x):\n        \"\"\" Evaluates derivative of polynomial with coefficients xs at point x.\"\"\"\n        return sum([i * coeff * math.pow(x, i - 1) for i, coeff in enumerate(xs)])\n\n    # Newton's method to find roots\n    guess = len(xs) / 2  \n    while abs(poly(xs, guess)) > 0.000001:\n        guess -= poly(xs, guess) / poly_prime(xs, guess)\n        \n    return guess\n", "stats": {"num_rollouts": 59, "num_generations": 13, "eval_time": "155.3365s", "mean_test_time": "4.5325s"}}
{"task_id": "HumanEval/38", "completion": "\n    # split string to groups. Each of length 3.\n    groups = [s[(3 * i):min((3 * i + 3), len(s))] for i in range((len(s) + 2) // 3)]\n    # cycle elements in each group back. Unless group has fewer elements than 3.\n    groups = [(group[-1] + group[:-1]) if len(group) ==3 else group for group in groups]\n    return \"\".join(groups)\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "8.8476s", "mean_test_time": "2.2082s"}}
{"task_id": "HumanEval/44", "completion": "\n    if x == 0:\n        return '0'\n\n    result = []\n    while x > 0:\n        digit = x % base\n        result.append(str(digit))\n        x //= base\n\n    return ''.join(result[::-1])  # reverse the list and join into a string\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "7.9470s", "mean_test_time": "3.6166s"}}
{"task_id": "HumanEval/50", "completion": "\n    return \"\".join([chr(((ord(ch) - 5 - ord(\"a\")) % 26) + ord(\"a\")) for ch in s])\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.9703s", "mean_test_time": "2.2046s"}}
{"task_id": "HumanEval/53", "completion": "\n    return x + y\n\n", "stats": {"num_rollouts": 0, "num_generations": 1, "eval_time": "4.1222s", "mean_test_time": "3.1437s"}}
{"task_id": "HumanEval/87", "completion": "\n    coordinates = []\n    for i, row in enumerate(lst):\n        for j, item in enumerate(row):\n            if item == x:\n                coordinates.append((i, j))\n                \n    return sorted(coordinates, key=lambda tup: (tup[0], -tup[1]))\n", "stats": {"num_rollouts": 22, "num_generations": 6, "eval_time": "49.5673s", "mean_test_time": "3.5555s"}}
{"task_id": "HumanEval/113", "completion": "\n    def count_odd_numbers(s):\n        return sum([int(c) % 2 for c in s])\n\n    result = []\n    for idx, elem in enumerate(lst):\n        odd_count = count_odd_numbers(elem)\n        result.append(\"the number of odd elements {}n the str{}ng {} of the {}nput.\".format(odd_count, odd_count, odd_count, odd_count))\n    return result\n", "stats": {"num_rollouts": 13, "num_generations": 3, "eval_time": "27.1449s", "mean_test_time": "2.7579s"}}
{"task_id": "HumanEval/151", "completion": "\n    return sum([i**2 for i in lst if type(i)==int and i > 0 and i%2 != 0])\n\n", "stats": {"num_rollouts": 18, "num_generations": 5, "eval_time": "34.2715s", "mean_test_time": "3.5269s"}}
